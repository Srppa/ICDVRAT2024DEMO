<!doctype html>
<html>

<head>
    <title>ICDVRAT2024</title>
    <meta name="description" content="Web for ICDVRAT conference">
    <meta name="keywords" content="ICDVRAT VR Virtual Reality Conference">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,400;0,500;0,900;1,400&display=swap"
        rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.1.min.js"
        integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>


    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.css"
        integrity="sha512-wR4oNhLBHf7smjy0K4oqzdWumd+r5/+6QO/vDda76MW5iug4PT7v86FoEkySIJft3XA0Ae6axhIvHrqwm793Nw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.css"
        integrity="sha512-6lLUdeQ5uheMFbWm3CP271l14RsX1xtx+J5x2yeIDkkiBpeVTNhTqijME7GgRKKi6hCqovwCoBTlRBEC20M8Mg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"
        integrity="sha512-XtmMtDEcNz2j7ekrtHvOVR4iwwaD6o/FUJe6+Zq+HgcCsk3kj4uSQQR8weQ2QVj1o0Pk6PwYLohm206ZzNfubg=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
</head>

<body>
    <header class="speaker-page-header" style="background-image: url(/images/background.jpg)">
        <img class="logo-wide-top" src="/images/logo_wide.png" />
        <div class="speaker-page-header-innner">
            <a class="speaker-page-header-back" href="/Index.html#programLink">
                <img src="/images/arrow_white.png" class="speaker-page-header-back-img">
                <span>Back</span>
            </a>
            <div class="speaker-page-header-title">
                <img class="logo-wide" src="/images/logo_wide.png" />
                <h1>15th International Conference on Disability, Virtual Reality & Associated Technologies</h1>
            </div>
        </div>
    </header>
    <main class="program-page-main">
        <h2>Program</h2>
        <div class="select-day">
            <a class="selected">First Day</a>
            <a>Second Day</a>
            <a>Third Day</a>
            <a>Fourth Day</a>
        </div>
        <div class="day-info">
            <div class="day-info-halfes">
                <div class="day-info-falf">
                    <div class="presentation-type">
                        <img src="images/debate_black.png">
                        <p>Standard Podium Presentation (15&nbsp;min)</p>
                    </div>
                    <div class="presentation-type">
                        <img src="images/poster_black.png">
                        <p>Short Poster Presentation (8&nbsp;min)</p>
                    </div>
                </div>
                <div class="day-info-falf">
                    <div class="presentation-type">
                        <img src="images/debate_blue.png">
                        <p>CYBER Presentations PART 1+2 (12&nbsp;min)</p>
                    </div>
                    <div class="presentation-type">
                        <img src="images/poster_blue.png">
                        <p>CYBER Poster Presentations (5&nbsp;min)</p>
                    </div>
                </div>
            </div>
            <p class="abstract-info">To view the abstract<br class="info-break-fix"> click on the presentation title!</p>
        </div>
        <div id="programDays">
            <div id="apendee1" class="program-day">


                <div class="program-item simple">
                    <div class="time">08:00 onwards</div>
                    <div class="content grey-blue">Registration of the attendees</div>
                </div>

                <div class="program-item simple">
                    <div class="time">08:45</div>
                    <div class="content dark-blue">Conference opening</div>
                </div>

                <div class="program-item">
                    <div class="time">09:00 – 10:25</div>
                    <div class="content">
                        <div class="content-header light-blue">
                            <h4>Cyberspace, Behavior and e-Therapy (CYBER) – Part 1</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Iveta Fajnerova</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Suriia Akhmetova &amp;. Misgana
                                            Desalegne</span><span class="inbetween"> – </span><span
                                            class="content-item-title">VR-based training for improvement of positive
                                            body image: A Pilot Study</span></p>
                                </div>
                                <p class="content-item-abstract">This study aimed to evaluate the impact of ACT-based
                                    intervention on body image flexibility and body awareness of healthy participants.
                                    Using virtual reality as a main tool, the study implemented mixed-methods design,
                                    and the data from 14 people was collected. Findings revealed statistically
                                    significant improvement with a large effect size for body image flexibility. Future
                                    considerations include a larger and more diverse sample and a refinement of
                                    measurement tools.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Urme Bose &amp;. Bryan Hilanga</span><span
                                            class="inbetween"> – </span><span class="content-item-title">A longitudinal
                                            exploratory study of neurophysiological reactions among young adults during
                                            psychometric testing</span></p>
                                </div>
                                <p class="content-item-abstract">Our goal is to investigate the integration of
                                    self-report and neurophysiological data in a new measurement system. Multi-sensor
                                    and multimodal methods were used through longitudinal follow-up at one-week
                                    intervals across three sessions. We tracked individuals' scores to analyze their
                                    evolution over time and establish meaningful correlations within each participant.
                                    Psychometric tests such as Hospital Anxiety and Depression Scale (HADS) and
                                    State-Trait Anxiety Inventory (STAI-S) were used to correlate self-report measures
                                    of anxiety and depression with neurophysiological measures. Control psychometric
                                    measures such as 10-Item Big Five Inventory (BFI-10), STAI-T, and Fear Questionnaire
                                    (FQ) were also included. We collected a significant quantity of raw data from
                                    eye-tracking and heart rate variability (HRV) sensors from (n=4) resulting in a
                                    comprehensive dataset used for data analysis. Preliminary results showed that on
                                    average for each participant HRV, fixation, and saccade rate were higher during
                                    psychometric testing compared to the baseline measurement. With high-quality sensors
                                    that provide accurate physiological data we can create more personalized predictive
                                    models for anxiety and depression with machine learning (ML), potentially enabling
                                    their use in psychological assessments in the coming years.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Ling Zeng &amp;. Maria Hashmi</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Multisensory
                                            Integration and Embodiment: A Virtual Reality-Based Study</span></p>
                                </div>
                                <p class="content-item-abstract">MultiSensory Integration (MSI) is at the basis of our
                                    everyday experiences, including Body Self Consciousness (BSC). MSI refers to both
                                    the integration of information from different sensory modalities (e.g., visual and
                                    tactile) and spatial frames (first person perspective (1PP) and third-person
                                    perspective (3PP). The link between MSI and BSC is well represented by Body
                                    Illusions, which uses multisensory conflicts to make individuals perceive an
                                    artificial body as their own body. In this study, we investigated if and how MSI
                                    abilities influence embodiment strength. Participants experienced an artificial body
                                    within an immersive virtual environment from both 1PP and 3PP, while undergoing
                                    visuo-tactile stimulation that varied between synchronous and asynchronous
                                    conditions.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Laura Valentina Lesmes Castañeda &amp;. Selin
                                            Saglam</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Gamification of a VR Task to Modify Attentional
                                            Bias Towards Body Parts Related to Weight</span></p>
                                </div>
                                <p class="content-item-abstract">This investigation explored the impact of a gamified
                                    virtual reality (VR) task on attentional biases by leveraging "BodyGaze Game: The
                                    Bathing Ritual" to alter attentional biases towards body parts related to weight. We
                                    enlisted forty healthy adults and assessed their user experience via the GAMEX and
                                    SUS scales. A randomized controlled trial, aimed at contrasting gamified with
                                    non-gamified approaches, was developed for this purpose. No significant differences
                                    in usability were found between the groups (SUS, p = 0.38), but the gamified group
                                    showed high satisfaction (GAMEX mean = 76.45) with notable enjoyment (mean = 19) and
                                    absorption (mean = 22.75). These findings suggest that gamification enhances
                                    specific user experiences like enjoyment and immersion, though overall usability was
                                    similar across both groups.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Wu Panzifan &amp;. Maria Castro</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Exposure
                                            therapy in Virtual Reality for children and adolescents with selective
                                            mutism: A usability pilot study</span></p>
                                </div>
                                <p class="content-item-abstract">In this study, exposure therapy in Virtual Reality (VR)
                                    intervention was first designed to improve the social skills of children and
                                    adolescents with Selective Mutism (SM). Afterwards, we tested the intervention's
                                    usability, asking patients to engage with the exposure therapy in the VR system to
                                    assess its functionality and provide a feedback program. Three patients participated
                                    and were assessed with different questionnaires on anxiety and usability.
                                    Preliminary results show high acceptance of the interaction with the program and
                                    variability in communication.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">10:25 – 10:45</div>
                    <div class="content light-grey">Coffee break</div>
                </div>

                <div class="program-item">
                    <div class="time">10:45 – 12:30</div>
                    <div class="content">
                        <div class="content-header light-blue">
                            <h4>Cyberspace, Behavior and e-Therapy (CYBER) – Part 2</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Nicholas Shopland</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Prince Paul Appiah</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Predicting
                                            Dropout at an Innovative Tech-focused Vocational Education Program using
                                            Machine Learning</span></p>
                                </div>
                                <p class="content-item-abstract">This study presents a Machine Learning (ML) model to
                                    predict student dropout at a free after-school e-learning program. The best
                                    performing prediction model was found to be random forest, which achieved a
                                    prediction accuracy of 90.2%, precision of 90.3%, recall of 90.3%, and F1-score of
                                    90.2%. using predictors that fall under 3 categories: reported pathologies,
                                    sociodemographics, and pedagogic engagement. The most significant factors used in
                                    predicting dropout at TUMO were found to be the pedagogic engagement factors, as the
                                    top ten predictors were all part of this category. To a lesser extent,
                                    sociodemographic factors influence dropout and reported pathologies were found to
                                    not be significant predictors of dropout by themselves but more so when a student is
                                    affected by more than one physical or mental health issue. The pathology category
                                    with the more significant effect on dropout behavior was learning disorders.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Ilia Kulagin &amp;. Daniel Velez
                                            Marin</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Exploring Verbal Speech Patterns to assess
                                            Attachment Style and tendencies towards Anxiety and Depression</span></p>
                                </div>
                                <p class="content-item-abstract">This study explores the potential of using a Large
                                    Language Model (LLM) to analyze verbal speech patterns to assess attachment styles
                                    and tendencies toward anxiety and depression. A diverse sample of 50 adults
                                    participated in the study. Participants were presented with images based on the
                                    Adult Attachment Projective Picture System (AAP) and asked to describe the scenes,
                                    with their responses transcribed and analyzed by the LLM. The LLM's identification
                                    of attachment styles showed a 58% true positive rate compared to the Relationship
                                    Questionnaire (RQ). The LLM overestimated anxiety and underestimated depression
                                    compared to the Hospital Anxiety and Depression Scale (HADS). These findings suggest
                                    that while LLMs show promise in attachment assessment, further refinement in context
                                    and prompt engineering is needed to improve accuracy, particularly concerning
                                    anxiety and depression evaluations. The study underscores the potential for
                                    automated tools in psychological assessment, paving the way for future research in
                                    this domain.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Javad Modaresi &amp;. Rafael
                                            Paulino</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Multisensory Integration and Embodiment: A
                                            Virtual Reality-Based Study</span></p>
                                </div>
                                <p class="content-item-abstract">MultiSensory Integration (MSI) is at the basis of our
                                    everyday experiences, including Body Self Consciousness (BSC). MSI refers to both
                                    the integration of information from different sensory modalities (e.g., visual and
                                    tactile) and spatial frames (first person perspective (1PP) and third-person
                                    perspective (3PP). The link between MSI and BSC is well represented by Body
                                    Illusions, which uses multisensory conflicts to make individuals perceive an
                                    artificial body as their own body. In this study, we investigated if and how MSI
                                    abilities influence embodiment strength. Participants experienced an artificial body
                                    within an immersive virtual environment from both 1PP and 3PP, while undergoing
                                    visuo-tactile stimulation that varied between synchronous and asynchronous
                                    conditions.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Sadia Maqsood</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Cybersecurity Assessment and Training
                                            Simulator In Virtual Reality for Workplace Employees</span></p>
                                </div>
                                <p class="content-item-abstract">In response to the escalating cybersecurity challenges
                                    worldwide, this study introduced a virtual reality simulator to assess and train
                                    individuals (N=18) in an organization’s work setting for mitigating the risk of
                                    cyberattacks. This realistic simulator experience incorporates personalized feedback
                                    within real-world scenarios. Results show that the VR task increased online privacy
                                    awareness regarding information sharing. Further, performance in the VR task can
                                    predict the risk propensity of individuals. This work can be used to educate
                                    businesses and governments to follow more robust cybersecurity practices in
                                    organizations.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Fernanda Lima Pimentel &amp;. Sandip
                                            Bhusal</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Assessing Oxygenation Changes using fNIRS in a
                                            Time-Pressure Task</span></p>
                                </div>
                                <p class="content-item-abstract">This study investigates anxiety detection using HRV,
                                    EDA, and fNIRS biosignals in 30 participants at Lusofona University. Significant
                                    physiological changes were observed during tasks, especially in oxyhemoglobin
                                    levels, measured by fNIRS, highlighting this sensor’s potential in detecting
                                    anxiety-related cerebral blood flow changes.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_blue.png">
                                    <p><span class="content-item-authors">Oluwatobiloba Sodade &amp;. Yusuf
                                            Sani</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Psychology of Frailty and Prediction of Fall
                                            among Elderly People Living in French Nursing Homes</span></p>
                                </div>
                                <p class="content-item-abstract">Psychological frailty is less researched and is often
                                    operationalized to include the co-occurrence of physical frailty with low mood,
                                    apathy, depression, and cognitive deficits. In this study, we adopted a
                                    multicentric, longitudinal, and quantitative approach spanning over six months; that
                                    involved a monthly assessment of elderly participants aged 65 and above living in
                                    emeis group’s nursing homes. We have assessed anxiety, cognitive impairment, and
                                    depression and their influence on the risk of falls, and also train a machine
                                    learning model that could predict the risk of falls on our small sample size to test
                                    it on a similar larger group</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">12:30 – 13:30</div>
                    <div class="content light-grey">Lunch (provided)</div>
                </div>

                <div class="program-item">
                    <div class="time">13:30 – 14:00</div>
                    <div class="content">
                        <div class="content-header dark-blue heightFix">
                            <h4>Welcome session</h4>
                            <h4 class="extra"></h4>
                            <h5>Iveta Fajnerová, Jiří Horáček, Lenka Lhotská</h5>
                        </div>
                        <div class="content-items">

                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">14:00 – 15:00</div>
                    <div class="content">
                        <div class="content-header orange">
                            <h4>Keynote talk: Professor Maria T Schultheis</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Bonnie Connor</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="images/star_black.png">
                                    <p><span class="content-item-authors"></span><span
                                            class="content-item-title">"Technology &amp; Cognition": Examining new
                                            trends and opportunities</span></p>
                                </div>
                                <p class="content-item-abstract">New technology trends continue to grow rapidly and they
                                    offer the potential to change the way we understand brain functioning and
                                    brain-behavior interactions. The clinical application of these technologies
                                    continues to require the understanding of both the benefits and limitations of
                                    integrating these novel methodologies to the needs of the population served.
                                    Established technologies, such as virtual reality and neuroimaging can provide
                                    examples of the transition from the lab to the clinic. Other emerging technologies,
                                    such as neuromodulation and brain-computer interface devices offer new opportunities
                                    for brain-behavior specialists. This workshop will offer an overview of key lessons
                                    learned in the clinical translation of technologies and discuss important
                                    considerations for novel technologies that offer new opportunities.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">15:00 – 16:00</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 1: VR exposure - Trauma</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: TBS</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Michael Roy</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Computer Monitor versus Augmented
                                            Reality: Expanding 3MDR Therapy for PTSD: A Randomized Controlled Trial
                                            (CARE4PTSD)</span></p>
                                </div>
                                <p class="content-item-abstract">This presentation will review results of our successful
                                    first study involving the novel Multi-modular Memory Desensitization and
                                    Reconsolidation (3MDR) “walk and talk” PTSD therapy. While there were 2 prior
                                    publications on 3MDR in Dutch and British veterans, our study was unique in being
                                    the first to address military personnel with both PTSD and TBI, the first to include
                                    significant numbers of women (50%), and in demonstrating that the eye movement
                                    element of 3MDR added significant benefit, by randomizing participants to either
                                    receive this element or not. We will also provide preliminary results of our efforts
                                    to deliver 3MDR less expensively.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Raúl Durón-Figueroa</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Development and
                                            Usability Evaluation of Virtual Environments for the Treatment of
                                            Post-Traumatic Stress Disorder in Earthquake Victims</span></p>
                                </div>
                                <p class="content-item-abstract">TBS</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Albert Rizzo</span><span class="inbetween"> –
                                        </span><span class="content-item-title">The Virtual Ukraine Project: Trauma
                                            Therapy in Warzones with Virtual Reality</span></p>
                                </div>
                                <p class="content-item-abstract">The "Virtual Ukraine Project," utilizes Virtual Reality
                                    (VR) and the Metaverse to address the psychological impacts of the Ukrainian
                                    conflict on military personnel and civilians. Leveraging these technologies, the
                                    project has four primary initiatives: (1) Adapting the BRAVEMIND VR Exposure Therapy
                                    (VRET) system for PTSD treatment to reflect the Ukrainian conflict, creating
                                    relevant virtual environments for therapeutic exposure. (2) Employing a digital
                                    version of Sandtray therapy for Ukrainian children affected by Adverse Childhood
                                    Experiences, allowing for narrative play and emotional expression. (3) Developing a
                                    metaverse-enabled social support application, facilitating clinician-driven and
                                    peer-supported group processes for displaced individuals, offering a platform for
                                    emotional support and shared experiences. (4) Integrating "The Sanctuary," a VR
                                    application for mindfulness, meditation and relaxation activities, serving as a
                                    supplementary tool for stress and trauma management. Highlighting VR's potential for
                                    immersive therapy, the project aims to provide a comprehensive set of VR tools for
                                    mental health care in conflict zones, demonstrating VR's innovative, accessible, and
                                    culturally sensitive therapeutic possibilities.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">16:00 – 16:30</div>
                    <div class="content light-grey">Coffee break</div>
                </div>

                <div class="program-item">
                    <div class="time">16:30 – 17:20</div>
                    <div class="content">
                        <div class="content-header medium-blue">
                            <h4>Session 2: VR exposure – Anxiety disorders</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Albert Skip Rizzo</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Soledad Quero</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Overcoming traditional exposure
                                            treatments: Preliminary results from a Randomized Controlled Trial
                                            evaluating the efficacy of Projection-Based Augmented Reality Exposure
                                            Treatment for cockroach phobia</span></p>
                                </div>
                                <p class="content-item-abstract">In vivo exposure treatment (IVET), although effective,
                                    has limitations related to the availability and acceptability of phobic stimuli.
                                    Augmented reality (AR) offers multiple options that can potentially improve
                                    treatment efficiency and acceptance. This study investigates the effectiveness of a
                                    projection-based AR exposure treatment (P-ARET) compared to IVET for cockroach
                                    phobia. The results showed that both P-ARET and IVET significantly improved symptoms
                                    compared to a waitlist control group, with benefits sustained over time. However,
                                    although no significant differences were found between the active conditions, P-ARET
                                    obtained better scores in terms of participants' experience.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Soledad Quero</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Enhancing exposure therapy
                                            effectiveness: projection-based augmented reality for specific cockroach
                                            phobia treatment compared to traditional treatment regarding stimuli
                                            variability</span></p>
                                </div>
                                <p class="content-item-abstract">Although in vivo exposure is the preferred treatment
                                    for specific phobia, its limitations regarding the availability and acceptability of
                                    phobic stimuli prompt exploration of the potential of other alternatives to improve
                                    exposure therapy. This study examines the stimuli variability offered by
                                    projection-based augmented reality exposure versus in vivo exposure and a wait-list
                                    group in a sample of patients diagnosed with cockroach phobia. Results show that
                                    both active treatments significantly reduced phobia symptoms compared to the control
                                    and maintained the improvements over time. However, the variability of the stimulus
                                    offered by augmented reality was not a determining factor of effectiveness.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Markéta Jablonská</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Design and
                                            Evaluation of Virtual Environments for Exposure Therapy of Aviophobia: Early
                                            Feasibility Study</span></p>
                                </div>
                                <p class="content-item-abstract">Aviophobia is a type of specific phobia characterized
                                    by a persistent fear of flying negatively affecting people’s professional and social
                                    life. This study aims to evaluate a newly developed virtual environment for exposure
                                    therapy of aviophobia using a comparison of subjective anxiety ratings between an
                                    experimental and a control group. The main focus is on the usability of the
                                    environment and its capability to induce anxiety in people with aviophobia. The
                                    preliminary results show a great potential of the tested virtual environment in
                                    inducing anxiety in people with the fear of flying compared to the healthy control
                                    group.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Barbora Darmová</span><span class="inbetween">
                                            – </span><span class="content-item-title">Evaluating Virtual Scenarios
                                            through the Lens of the Contrast Avoidance Model in the Context of
                                            Generalized Anxiety Disorder Treatment</span></p>
                                </div>
                                <p class="content-item-abstract">This study explores the application of the Contrast
                                    Avoidance Model (CAM) within virtual reality exposure therapy (VRET) for treating
                                    generalized anxiety disorder (GAD). Recognizing GAD's pervasive impact and the
                                    limitations of traditional cognitive-behavioral therapy (CBT), this research aims to
                                    design, implement, and evaluate CAM-based intervention that addresses negative
                                    contrast sensitivity in GAD patients. We hypothesize that exposure to controlled,
                                    discomfort-evoking VR scenarios, coupled with relaxation, can enhance patients'
                                    coping mechanisms and reduce anxiety symptoms (Newman et al., 2011). This study
                                    zeroes in on evaluating VR scenarios to confirm they trigger negative emotions in
                                    GAD patients, crucial for their use in the proposed treatment.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">17:20 – 18:20</div>
                    <div class="content">
                        <div class="content-header light-blue">
                            <h4>Cyberspace, Behavior and e-Therapy (CYBER) – Poster session</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Matthew Harris &amp; Michal Sedlak</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Jiayao Chen &amp;. Suvechhaya
                                            Shrestha</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Enhancing Emotional Connection and Engagement in
                                            Long-Distance Relationships: A Comparative Study of Virtual Reality and
                                            Video Calls</span></p>
                                </div>
                                <p class="content-item-abstract">This study investigates the effectiveness of virtual
                                    reality (VR) versus video calls in enhancing emotional connection and engagement
                                    during daily catch-up calls among geographically separated family members or
                                    friends. The study will be conducted using VR United, a virtual reality application
                                    that enables multiple users to interact together in virtual reality within the same
                                    environment, each one with an avatar that looks like themselves. We will compare
                                    three experimental conditions: Video call, Virtual Reality call, and Passthrough
                                    Virtual Reality call. Utilizing a mixed-methods approach, we assess the sense of
                                    co-presence, emotional closeness, and engagement of the conversations through
                                    self-report questionnaires, interviews, and behavioral observations in these 3
                                    experimental conditions. We will analyze the qualitative findings using sentiment
                                    analysis. Findings will provide insights into how Virtual Reality might support
                                    long-distance familial or friendship relationships.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Kátia dos Santos Estevães &amp;. Abigya
                                            Melese</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Transforming perspectives: the impact of virtual
                                            embodiment on attitudes and responses to gender-based harassment in the
                                            metaverse</span></p>
                                </div>
                                <p class="content-item-abstract">In this study, we explore the impact of virtual reality
                                    (VR) on male participants' attitudes and helping behavior towards victims of
                                    gender-based harassment (GBH) in the metaverse. Sixty participants will be randomly
                                    assigned to either a harassment condition, where they embody a female avatar
                                    experiencing sexual harassment, or a control condition, with no harassment. Pre- and
                                    post-exposure measures will assess changes in attitudes, while a VR scene will
                                    evaluate the potential for encouraging bystander intervention. Results will
                                    contribute to understanding VR's effectiveness in preventing harassment in the
                                    metaverse by changing perspective through embodiment.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Vaishali Goyal &amp;. Gustavo Menegon
                                        </span><span class="inbetween"> – </span><span class="content-item-title">The
                                            temporal neural dynamics of aesthetic appreciation for visual art</span></p>
                                </div>
                                <p class="content-item-abstract">Neuroaesthetics researches brain activity during
                                    aesthetic experiences, which are common when viewing visual art such as paintings.
                                    However, we know very little about how aesthetic experiences during art appreciation
                                    unfold across time in the human brain. This work aims to investigate the temporal
                                    neural correlates of aesthetic experiences with different types of artworks.
                                    Participants will view a wide range of visual artworks while we record EEG data. The
                                    resulting EEG response patterns will be analyzed in a multivariate representational
                                    similarity analysis (RSA) framework, which will allow us to link participants’
                                    explicit ratings of visual aesthetic appeal to their emerging temporal brain
                                    dynamics. Our study will clarify how rapidly the brain encodes the aesthetic appeal
                                    of visual art, and which features of the artworks enable the emergence of such
                                    beauty-related signals.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Esra Bayısın &amp;. Asmar Khalilli</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Using
                                            artificial intelligence to model cognitive load and adapt challenging tasks
                                            during immersions in virtual reality: Phase 1 – a literature review and
                                            study protocol for people diagnosed with schizophrenia</span></p>
                                </div>
                                <p class="content-item-abstract">Artificial intelligence techniques offer the potential
                                    of improving the effectiveness of cognitive remediation tools by adapting their
                                    difficulty in real time based on the cognitive load of users immersed in virtual
                                    reality (VR). The presentation aims to (a) report on a scoping literature review
                                    documenting the literature on cognitive load, VR, and schizophrenia and (b) describe
                                    the study protocol of an upcoming experiment on the usability of adaptive VR
                                    environments designed for cognitive remediation in people diagnosed with
                                    schizophrenia. The themes emerging from the scoping review guided the selection of
                                    extraneous cognitive loads that will be tested in 12 VR scenarios.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Nina Belousova, Mariam Barseguyan &amp;.
                                            Vladimir Zyablov</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Psychological Impact of Breast Cancer and
                                            Premature Menopause: Digital Intervention Approach</span></p>
                                </div>
                                <p class="content-item-abstract">This study explores the psychological effects of breast
                                    cancer and premature menopause on mental health, highlighting increased risks of
                                    depression and anxiety. A digital intervention using wearable devices aims to
                                    monitor patients' mental health and physical activity, providing timely
                                    psychological support. Over 6 months, 20 breast cancer patients experiencing
                                    premature menopause will participate, undergoing physical data collection and
                                    psychometric assessments. Statistical analysis will examine the links between
                                    physical activity and mood/anxiety symptoms to guide the development of effective
                                    interventions for these mental health challenges.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Miltiadis Gialousis &amp;. Diogo
                                            Gomes</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Psychological Trait Assessment Prior to
                                            Therapeutic Sessions using Open-Ended Questions</span></p>
                                </div>
                                <p class="content-item-abstract">Initial therapeutic interviews are crucial for
                                    establishing a positive therapeutic relationship, and a better understanding of the
                                    patient's psychological traits may help match patients with compatible therapists
                                    and prepare them for the initial conversation. This study aims to develop AI models
                                    for the psychological screening of patients prior to therapy, recognizing core
                                    psychological traits. Our methodology involves defining core psychological traits
                                    and developing text-based and speech-based deep learning models tailored to assess
                                    those individual psychological traits. This approach is expected to enable
                                    therapists to optimize therapy sessions based on pre-session insights and improve
                                    therapy outcomes.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">David Felipe Vega Villa &amp;. Vaihbav
                                            Mehra</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Can an LLM-equipped Multimodal Chatbot adapted to
                                            psychological techniques improve Mental Wellbeing? A preliminary study
                                            description</span></p>
                                </div>
                                <p class="content-item-abstract">The use of agents such as chatbots in mental health
                                    care approaches, have shown promising results. Advances through the integration of
                                    Language Large Models (LLM) and other modalities of information (different from
                                    textual) could provide agents with a more dynamic and contextual engagement,
                                    although limitations still hinder effective interactions. With this in mind, we aim
                                    to develop and evaluate an LLM-equipped multimodal chatbot adapted to evidence-based
                                    techniques from positive psychology and effective planning to improve mental
                                    wellbeing. Remote/virtual users will participate, and self-report questionnaires
                                    will be administered for pre-post testing, which will be analyzed alongside the
                                    multimodal data.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_blue.png">
                                    <p><span class="content-item-authors">Bruna Filipa Augusto da Silva, Jana Subirana
                                            &amp;. Amir Ansari</span><span class="inbetween"> – </span><span
                                            class="content-item-title">Enhancing Personality Assessment: From
                                            Self-Reported Questionnaires to Deep Learning Predictions</span></p>
                                </div>
                                <p class="content-item-abstract">This study explores new methodologies for personality
                                    assessment using deep learning models and audiovisual cues, building on the
                                    traditional Big Five Factor Model. The UDIVA v0.5 dataset, featuring multimodal,
                                    multiview videos of dyadic interactions, serves as the primary data source.
                                    Participants completed self reported personality questionnaires. The study aims to
                                    enhance personality predictability by analyzing behavioral cues like gaze, gestures,
                                    and vocal characteristics. Features extracted from the dataset will be used in a
                                    transformer-based, context-aware model to regress personality traits. This research
                                    seeks to identify behavioral cues that correlate with personality traits and improve
                                    prediction accuracy.</p>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
            <div id="apendee2" class="program-day">


                <div class="program-item">
                    <div class="time">09:00 – 10:20</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 3: Autism – Assessment Tools &amp; Participatory Design</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: William Farr &amp; Bonnie Connor</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Isaac Lee</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Can an LLM AI-Augmented ADI-R Improve
                                            Diagnostic Pathways and Educational Outcomes for Autistic
                                            Individuals?</span></p>
                                </div>
                                <p class="content-item-abstract">There are several significant issues in Autism
                                    diagnostics today including gender, race, and socioeconomic bias and the phenomenon
                                    of subjective observational inventories which are exacerbated for individuals with
                                    autism without intellectual disability. Even “gold standard” diagnostic tools like
                                    the ADI-R suffer from cost, time, accuracy, efficiency, and scalability issues. A
                                    promising and emerging area of study within this field is concerned with the
                                    applicability of LLM AI. This paper will argue for a theoretical framework
                                    surrounding the potential augmentation of the ADI-R using LLM AI to improve both
                                    diagnostic pathways and educational outcomes for individuals with autism without
                                    intellectual disability.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">William Farr</span><span class="inbetween"> –
                                        </span><span class="content-item-title">External Fine Motor Markers of
                                            Neurodivergence: Pilot Results of the Tang Ball</span></p>
                                </div>
                                <p class="content-item-abstract">At two previous ICDVRAT conferences (2018, 2022) the
                                    authors reported on the concept, and then development phase of a tangible toy that
                                    could be used to assist in the diagnosis of autism in pre-school children. Here,
                                    results of the first round of testing on the intended user group are reported.
                                    Results show variation between pre-school neurodivergent and neurotypical
                                    populations as predicted in terms of speed and accuracy of movement. Fine motor
                                    movement can be a potential biomarker for autism that would be less dependent on
                                    observational data, and more objective.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Sean Haddick</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Through The Eyes of An Autistic Child:
                                            The Role of Technology and Autistic Researchers in Developing
                                            Interventions</span></p>
                                </div>
                                <p class="content-item-abstract">TBS</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Pascal Meital</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Online Course for Autistic Adults:
                                            Usability Study and Participatory Design</span></p>
                                </div>
                                <p class="content-item-abstract">This paper explores the development process of an
                                    online course for autistic adults. Three studies were conducted: usability study,
                                    participatory design study, and pilot evaluation study. Key findings emphasize the
                                    importance of customization of the presentation of information, clarity in
                                    instruction delivery, mitigation of distractions, and motivation enhancement during
                                    possible challenges. Insights highlight the need to accommodate unique perceptual
                                    traits, adapt instructions, foster a clear learning environment, and address
                                    possible challenges sensitively. These findings inform the design of effective
                                    online courses tailored for autistic adults.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">10:20 – 10:50</div>
                    <div class="content light-grey">Coffee break</div>
                </div>

                <div class="program-item">
                    <div class="time">10:50 – 11:30</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 4: Autism – Social Skills &amp; Public Transport</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: William Farr</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Ali Adjorlu</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Virtual Station: Virtual Reality as a
                                            Bridge to Independence in Public Transportation for Autistic Youth</span>
                                    </p>
                                </div>
                                <p class="content-item-abstract">In this paper, we present a virtual reality application
                                    designed to prepare autistic children for independent use of public transportation.
                                    A virtual subway train station is designed to look similar to a real train station
                                    in Copenhagen next to a special education school. This extended abstract describes
                                    the VR intervention, the results of an explorative evaluation, and future iterations
                                    of the project.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Ali Adjorlu</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Enhancing Social Skills in Autism
                                            Spectrum Disorder: A Virtual Reality Intervention for Educational
                                            Settings</span></p>
                                </div>
                                <p class="content-item-abstract">In this paper, we explore the use of a Virtual Reality
                                    (VR) environment designed for special education teachers to enhance the social
                                    skills of children with Autism Spectrum Disorder (ASD).The effectiveness of this
                                    tool was preliminarily evaluated by European teachers during a Learning, Teaching,
                                    and Training Event under the Erasmus+ GAMESS project. Initial feedback from the
                                    participants, teachers from multiple European countries, indicates a positive
                                    attitude towards integrating VR in education, though some reservations about
                                    technology use were noted. The findings suggest that VR could be a supportive tool
                                    in special education for enhancing learning experiences and social interaction among
                                    autistic children.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Sean Haddick</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Metahumans: A Framework for Assessment
                                            and Feedback of Social-Emotional Reciprocity</span></p>
                                </div>
                                <p class="content-item-abstract">Current assessment and training in regard to Facial
                                    Emotion Expression Recognition (FEER) indicates that deficits in mimicry or
                                    mirroring—nonverbal behaviours used for social communication and social
                                    interaction—are a major contributing factor to deficiencies in that ability in
                                    persons with Autism Spectrum Disorder (ASD) and Alexithymia. This paper proposes a
                                    testing and potential training framework that utilises modern games technology,
                                    namely High Realism Virtual Humans, combined with live motion capture to encourage
                                    and aid in self-assessment of mimicry, proposing that in turn this could address
                                    deficits in FEER, and improve quality of life for persons with ASD and alexithymia.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">11:30 – 12:10 </div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 5: Sexolog</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Iveta Fajnerová</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Ali Adjorlu</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Virtual Sex Therapy: A virtual
                                            Psychotherapy Intervention to Help Individuals with Sexual Dysfunction
                                            Difficulties</span></p>
                                </div>
                                <p class="content-item-abstract">This paper presents a Virtual Reality (VR) based
                                    Psychotherapy intervention for sexual therapy for woman suffering from sexual
                                    dysfunctions. Our VR application is designed and developed in collaboration with a
                                    sex therapist and psychologist that aims to provide a confidential environment for
                                    psychosexual therapy, enhancing treatment efficacy and potentially creating a safe
                                    environment to receive therapy about a sensitive topic in a safe environment. The VR
                                    application as well as the planned evaluation of the intervention is described in
                                    this extended abstract.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Ondřej Vaníček</span><span class="inbetween">
                                            – </span><span class="content-item-title">Female sexual response to
                                            audiovisual stimuli in 2D/3D modality and first/third person
                                            perspective</span></p>
                                </div>
                                <p class="content-item-abstract">This study investigates the effect of sexually explicit
                                    video stimuli displayed in a different modality (3D vs. 2D) and perspective (first
                                    vs. third person) on female sexual arousal, both subjective and genital,
                                    pleasantness ratings, and sexual and general presence. The results are surprising
                                    and contrary to our expectation with 2D modality being superior to 3D in most of the
                                    measured variables.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">12:10 – 13:10</div>
                    <div class="content light-grey">Lunch (provided)</div>
                </div>

                <div class="program-item">
                    <div class="time">13:10 – 14:10</div>
                    <div class="content">
                        <div class="content-header orange">
                            <h4>Keynote talk: Mónica Spínola</h4>
                            <h4 class="extra">Penny Standen Best Early Career Paper Award Winner 2022</h4>
                            <h5>Chair: Iveta Fajnerová &amp; David Brown</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="images/star_black.png">
                                    <p><span class="content-item-authors"></span><span
                                            class="content-item-title">Functional Neuropsychological Assessment: past,
                                            present and future</span></p>
                                </div>
                                <p class="content-item-abstract">Over the last years, a paradigm shift in
                                    neuropsychological assessment has been observed: from a localizationist perspective
                                    to one focused on predicting everyday function. In numerous clinical disorders,
                                    cognitive deficits lead to compromises in functional abilities. However, current
                                    assessment instruments fail to be representative of real-world abilities, not
                                    allowing the prediction of the ability to perform activities of daily living.
                                    Technological solutions, such as virtual reality(VR) and wearable technologies, seem
                                    to be promising approaches in neuropsychological assessment, allowing the simulation
                                    of real-life situations(through VR) and real-time assessment of physiological
                                    measures(e.g., heart rate) that relate to cognition(e.g., cognitive workload). We
                                    will explore the development of innovative instruments that capture the advantages
                                    of performance-based metrics in real environments (through virtual simulations) and
                                    of objective information about the person’s internal state (through physiological
                                    measures).</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">14:10 – 15:30</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 6: Pain &amp; Palliative</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Sara Ventura</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Anna Zubková</span><span class="inbetween"> –
                                        </span><span class="content-item-title">The use of experiential VR to minimize
                                            anxiety in children with life limiting condition: A Randomized Control
                                            Trial</span></p>
                                </div>
                                <p class="content-item-abstract">This randomized controlled study involved pediatric
                                    patients (ages 10-18) with hemato-oncological or gastroenterological conditions.
                                    They were assigned to two groups: one receiving experiential VR intervention and the
                                    other, a video intervention followed by VR. Anxiety, pain, and fear levels were
                                    assessed before and after the interventions. The findings suggest that VR is
                                    effective in reducing anxiety and is particularly favoured over video distraction
                                    among participants who have experienced both interventions. Most patients found
                                    distraction helpful and expressed willingness to use VR repeatedly.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Martin Zielina</span><span class="inbetween">
                                            – </span><span class="content-item-title">Virtual Reality in Burn Treatment:
                                            A Comparative Study of High and Low Immersion Approaches on Pain and Anxiety
                                            Relief</span></p>
                                </div>
                                <p class="content-item-abstract">Virtual Reality (VR) interventions have emerged as a
                                    significant tool in medical treatments, particularly in reducing pain and anxiety
                                    during burn dressing changes. This study examines the effects of different VR
                                    immersion levels on pain (NPRS), anxiety (BSPAS), and presence (IPQ) during these
                                    procedures. We recruited 67 adult participants and randomly assigned them to either
                                    an experimental or a control group. The experimental group was subjected to a
                                    high-immersion VR environment known as Cold River, whereas the control group was
                                    exposed to a low-immersion environment featuring static images. Additionally, both
                                    groups underwent a dressing session without any VR intervention in a randomized
                                    design. Our findings indicate that VR, regardless of immersion level, significantly
                                    reduced pain and anxiety as compared to the non-VR condition.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Alexander Moreno</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Preliminary
                                            results of a systematic review of the use of virtual reality in palliative
                                            care</span></p>
                                </div>
                                <p class="content-item-abstract">Virtual reality (VR) has shown its potential in a
                                    variety of clinical applications. This systematic review aims to analyze VR studies
                                    conducted in pediatric, adult, and geriatric palliative care. Using COVIDENCE
                                    software, the screening process included 1005 records. After the independent review
                                    of the records, only 40 studies met the inclusion criteria. The preliminary findings
                                    before the final extraction process indicate that VR is a flourishing field in
                                    palliative care. The studies will be reviewed in the context of outcome measures and
                                    the type of VR intervention used, evaluating its feasibility, acceptability, and
                                    clinical efficacy.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Carolyn Thomas</span><span class="inbetween">
                                            – </span><span class="content-item-title">Existential Biophilic VR Therapy –
                                            Developing a Protocol for Care Settings</span></p>
                                </div>
                                <p class="content-item-abstract">An intervention protocol to assess health and wellbeing
                                    from biophilic Virtual Reality interventions, was elaborated to include existential
                                    theories identified from a scoping review. Additionally, a pilot study in care
                                    facilities was employed to assess the protocol’s feasibility. To comprehensively
                                    assess health and wellbeing outcomes for care home residents and individuals at
                                    end-of-life care, existential theories must be integrated. Meaning and purpose in
                                    life, agency, presence, legacy, and flow, are essential considerations for VR
                                    interventions in care settings and for maximising health and wellbeing outcomes.
                                    Finally, from the pilot study, existential aspects can effortlessly integrate within
                                    VR interventions, from the content creation to the research methods selection.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">15:30 – 16:00</div>
                    <div class="content light-grey">Coffee break</div>
                </div>

                <div class="program-item">
                    <div class="time">16:00 – 17:10</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 7: Cognition &amp; Spatial Navigation</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Cecilia Sik-Lanyi &amp; Renáta Cserjési</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Suhani Dheer</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Beyond Diagnosis: The Cognitive Demands
                                            of Stopping and Turning Behaviors Among Drivers With and Without Multiple
                                            Sclerosis and Implications for Driving Safety</span></p>
                                </div>
                                <p class="content-item-abstract">This study investigates the impact of multiple
                                    sclerosis (MS) and specific cognitive/motor functions on virtual reality-simulated
                                    driving behaviors, namely stopping and turning behavior, which are common sources of
                                    collisions. Findings suggest that while individuals with and without MS generally
                                    exhibit similar driving behaviors, subtle differences exist, especially for
                                    left-turns and complex intersections. Various cognitive/motor domains, including
                                    visuospatial ability and psychomotor speed, significantly influence driving
                                    behaviors across both groups. These findings emphasize the importance of taking
                                    cognitive and motor abilities into consideration when evaluating driving capability,
                                    underscoring road safety and independence for people with MS and the general
                                    population.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Matthew Harris</span><span class="inbetween">
                                            – </span><span class="content-item-title">Exploring the potential of using a
                                            Spatial Navigation Task to measure cognitive decline in adults with
                                            intellectual disabilities</span></p>
                                </div>
                                <p class="content-item-abstract">Due to its potential to offer a controlled environment
                                    for cognitive assessment, Virtual Reality (VR) has the potential to assess spatial
                                    navigation skills in those with intellectual disabilities (ID). An immersive virtual
                                    environment based on the triangle completion task (TCT) was co-designed and piloted
                                    with a research governance group comprising individuals with ID. Preliminary
                                    test-retest reliability was examined along with a comparison between the VR-based
                                    task and the Montreal Cognitive Assessment (MoCA), an established cognitive measure.
                                    Eight participants with ID completed the VR task across varying difficulty levels
                                    for between 2 and 4 sessions, with their performance assessed for reliability and
                                    correlation with MoCA scores. Results indicate poor test-retest reliability for the
                                    practice mode, while the version of the VR environment with limited visual cues
                                    difficulty showed better but still insufficient reliability. A weak correlation was
                                    observed for participants in terms of their performance measures within the version
                                    of the virtual environment containing limited visual cues and their MoCA scores
                                    suggesting the potential for using a virtual spatial navigation task in the
                                    assessment of cognitive decline in individuals with ID.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Kathryn N. Devlin</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Virtual Reality
                                            Driving Simulation May Enhance the Prediction of Real-World Unsafe
                                            Driving</span></p>
                                </div>
                                <p class="content-item-abstract">Virtual reality driving simulation (VRDS) may provide
                                    ecologically valid, objective, sensitive, and challenging measures of driving
                                    capacity than can complement existing driving evaluation tools. The present study is
                                    among the first to examine the association of VRDS metrics with real-world,
                                    naturalistic driving-as-usual. Results demonstrate that VRDS may enhance the
                                    prediction of naturalistic driving behaviours above and beyond existing
                                    neuropsychological assessments.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Mochammad Hannats Hanafi Ichsan</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Navigation in
                                            3D Virtual Environment for Older Adults</span></p>
                                </div>
                                <p class="content-item-abstract">Navigation is one of the main components in Virtual
                                    Reality (VR)/Virtual Environment (VE) or desktop VR. The interaction model in
                                    desktop VR comprises standard computer peripherals such as a monitor, keyboard, and
                                    mouse. Navigation techniques using mouse and monitor coordinates can be used as a
                                    navigation base model. Currently, older adults can still be productive by utilizing
                                    desktop VR. Various jobs/skill development in training or administration can be done
                                    so that older adults remain productive. To help older adults work, simplified VR
                                    navigation can reduce confusion and increase learnability. This pilot study proposes
                                    three forms of navigation in 3D VE that can be offered to improve navigation
                                    techniques in desktop VR based on design possibilities.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item">
                    <div class="time">17:10 – 18:00</div>
                    <div class="content">
                        <div class="content-header dark-blue">
                            <h4>Session 8: Emotions</h4>
                            <h4 class="extra"></h4>
                            <h5>Chair: Sean Haddick</h5>
                        </div>
                        <div class="content-items">


                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Alex Sumich</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Beneficial effects on subjective mood
                                            and brain function of biophilic quality in university environments shown in
                                            virtual reality</span></p>
                                </div>
                                <p class="content-item-abstract">Biophilic designs incorporate nature-based features
                                    into built environments. Raised theta activity is reported in biophilic
                                    environments. Virtual Reality allows greater control of experimental parameters than
                                    in-field studies. Participants provided subjective reports and underwent an
                                    electroencephalography assessment as they viewed interior spaces that varied (0 no
                                    features to 3 most features) in biophilic quality. Mood improved with biophilic
                                    quality. Theta power increased with biophilic quality for levels 1-3. Paradoxically,
                                    however, theta was also high in the condition devoid of biophilic features (Level
                                    0). Findings suggest that the benefit of biophilic environments on mood is
                                    paralleled by alterations in theta.</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/debate_black.png">
                                    <p><span class="content-item-authors">Jiří Pešek</span><span class="inbetween"> –
                                        </span><span class="content-item-title">Assessing emotional memory in VR</span>
                                    </p>
                                </div>
                                <p class="content-item-abstract">TBS</p>
                            </div>

                            <div class="content-item">
                                <div class="content-item-header">
                                    <img src="/images/poster_black.png">
                                    <p><span class="content-item-authors">Raissa de Oliveira Negrao</span><span
                                            class="inbetween"> – </span><span class="content-item-title">Exploring
                                            Emotional Responses to Virtual Reality Environments in Younger Adults</span>
                                    </p>
                                </div>
                                <p class="content-item-abstract">The study investigated the emotional responses of
                                    experienced and non-experienced virtual reality (VR) users to VR environments. While
                                    a discrete significant difference was found between the two groups, the findings
                                    suggest that positive affect may be associated with specific VR environments, as
                                    evidenced by a decline in Positive and Negative Affect Schedule (PANAS) scores for
                                    positive affect among experienced users. The observed pattern of increased
                                    excitement following exposure to the exciting VR condition and decreased excitement
                                    after a calm VR condition highlights the significant influence of VR experiences on
                                    emotional states. These findings underscore the potential of VR technology to
                                    modulate emotions and facilitate design of experiences for various applications,
                                    including entertainment, therapy, and education.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="program-item simple">
                    <div class="time">19:30 – 23:00</div>
                    <div class="content yellow"><span>Social evening &amp; dinner - <a href="https://icdvrat2024.lf3.cuni.cz/specials/social-evening">see Program Specials for details</a></span></div>
                </div>

            </div>
            <div id="apendee3" class="program-day">
            </div>

            <div id="apendee4" class="program-day">
                <span class="tbs">TBS</span>
            </div>
        </div>
    </main>
    <footer style="background-image: url(../images/background.jpg)">
        <p>© Copyright 2024 ICDVRAT 2024. All Rights Reserved.</p>
        <p>Web made by Pavel Srp</p>
    </footer>


    <template id="simpleProgramItemTemplate">
        <div class="program-item simple">
            <div class="time">
            </div>
            <div class="content">
            </div>
        </div>
    </template>


    <template id="complexProgramItemTemplate">
        <div class="program-item">
            <div class="time">
            </div>
            <div class="content">
                <div class="content-header">
                    <h4></h4>
                    <h4 class="extra"></h4>
                    <h5></h5>
                </div>
                <div class="content-items">

                </div>
            </div>
        </div>
    </template>

    <template id="contentItemTemplate">
        <div class="content-item">
            <div class="content-item-header">
                <img src="images/star_black.png">
                <p><span class="content-item-authors"></span><span class="inbetween"> – </span><span
                        class="content-item-title"></span></p>
            </div>
            <p class="content-item-abstract"></p>
        </div>
    </template>

    <template id="linkTemplate">
        <a class="link"></a>
    </template>

    <script>
        $(document).ready(function () {

            const simpleProgramItemTemplate = document.getElementById('simpleProgramItemTemplate');

            const complexProgramItemTemplate = document.getElementById('complexProgramItemTemplate');

            const contentItemTemplate = document.getElementById('contentItemTemplate');

            const linkTemplete = document.getElementById('linkTemplate');

            // Insert the cloned content into the container
            const apendee1Element = document.getElementById('apendee1');

            const apendee2Element = document.getElementById('apendee2');

            const apendee3Element = document.getElementById('apendee3');

            $.getJSON("/documents/program_list.json", function (json) {

                /*for(let i = 0; i < json.day1.length; i++){

                    let tempPart = json.day1[i];
                    if(tempPart.type == "simple"){
                        
                        const clone = simpleProgramItemTemplate.content.cloneNode(true);

                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content').innerText = tempPart.content.heading;
                        clone.querySelector('.content').classList.add(tempPart.content.color);

                        apendee1Element.appendChild(clone);
                    }
                    else{

                        const clone = complexProgramItemTemplate.content.cloneNode(true);

                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content-header h4').innerText = tempPart.content.heading;
                        clone.querySelector('.content-header h5').innerText = tempPart.content.subtext;
                        clone.querySelector('.content-header').classList.add(tempPart.content.color);

                        if(tempPart.content.talks.length < 1){
                            clone.querySelector('.content-header').classList.add("heightFix");
                        }

                        for(let j = 0; j < tempPart.content.talks.length; j++){

                            tempTalk = tempPart.content.talks[j]

                            const talkClone = contentItemTemplate.content.cloneNode(true);

                            talkClone.querySelector('.content-item-authors').innerText = tempTalk.authors;
                            if(tempTalk.authors == ""){
                                
                                talkClone.querySelector('.inbetween').remove()
                            }

                            talkClone.querySelector('.content-item-title').innerText = tempTalk.title;
                            talkClone.querySelector('.content-item-abstract').innerText = tempTalk.abstract;

                            if(tempTalk.icon == "blue-head"){
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_blue.png"
                            } else if ( tempTalk.icon == "black-head" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_black.png"
                            } else if ( tempTalk.icon == "blue-poster" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_blue.png"
                            } else if ( tempTalk.icon == "black-poster" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_black.png"
                            }
                            
                            clone.querySelector('.content-items').appendChild(talkClone);
                        }
                        apendee1Element.appendChild(clone);
                    }
                }*/

                /*for(let i = 0; i < json.day2.length; i++){

                    let tempPart = json.day2[i];
                    if(tempPart.type == "simple"){

                        const clone = simpleProgramItemTemplate.content.cloneNode(true);
                    
                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content').innerText = tempPart.content.heading;
                        clone.querySelector('.content').classList.add(tempPart.content.color);
                    
                        apendee2Element.appendChild(clone);
                    }
                    else{
                    
                        const clone = complexProgramItemTemplate.content.cloneNode(true);
                    
                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content-header h4').innerText = tempPart.content.heading;
                        clone.querySelector('.content-header h5').innerText = tempPart.content.subtext;
                        clone.querySelector('.content-header').classList.add(tempPart.content.color);
                    
                        if(tempPart.content.hasOwnProperty("extra")){
                            clone.querySelector('.extra').innerText = tempPart.content.extra;
                        }

                        if(tempPart.content.talks.length < 1){
                            clone.querySelector('.content-header').classList.add("heightFix");
                        }
                    
                        for(let j = 0; j < tempPart.content.talks.length; j++){
                        
                            tempTalk = tempPart.content.talks[j]
                        
                            const talkClone = contentItemTemplate.content.cloneNode(true);
                        
                            talkClone.querySelector('.content-item-authors').innerText = tempTalk.authors;
                            if(tempTalk.authors == ""){

                                talkClone.querySelector('.inbetween').remove()
                            }
                        
                            talkClone.querySelector('.content-item-title').innerText = tempTalk.title;
                            talkClone.querySelector('.content-item-abstract').innerText = tempTalk.abstract;
                        
                            if(tempTalk.icon == "blue-head"){
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_blue.png"
                            } else if ( tempTalk.icon == "black-head" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_black.png"
                            } else if ( tempTalk.icon == "blue-poster" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_blue.png"
                            } else if ( tempTalk.icon == "black-poster" ){
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_black.png"
                            }

                            clone.querySelector('.content-items').appendChild(talkClone);
                        }
                        apendee2Element.appendChild(clone);
                    }
                }*/

                for (let i = 0; i < json.day3.length; i++) {

                    let tempPart = json.day3[i];
                    if (tempPart.type == "simple") {

                        const clone = simpleProgramItemTemplate.content.cloneNode(true);

                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content').innerText = tempPart.content.heading;
                        clone.querySelector('.content').classList.add(tempPart.content.color);

                        apendee3Element.appendChild(clone);
                    }
                    else {

                        const clone = complexProgramItemTemplate.content.cloneNode(true);

                        clone.querySelector('.time').innerText = tempPart.time;
                        clone.querySelector('.content-header h4').innerText = tempPart.content.heading;
                        clone.querySelector('.content-header h5').innerText = tempPart.content.subtext;
                        clone.querySelector('.content-header').classList.add(tempPart.content.color);

                        if (tempPart.content.hasOwnProperty("extra")) {
                            clone.querySelector('.extra').innerText = tempPart.content.extra;
                        }

                        if (tempPart.content.talks.length < 1) {
                            clone.querySelector('.content-header').classList.add("heightFix");
                        }

                        for (let j = 0; j < tempPart.content.talks.length; j++) {

                            tempTalk = tempPart.content.talks[j]

                            const talkClone = contentItemTemplate.content.cloneNode(true);

                            talkClone.querySelector('.content-item-authors').innerText = tempTalk.authors;
                            if (tempTalk.authors == "") {

                                talkClone.querySelector('.inbetween').remove()
                            }

                            talkClone.querySelector('.content-item-title').innerText = tempTalk.title;
                            talkClone.querySelector('.content-item-abstract').innerText = tempTalk.abstract;

                            if (tempTalk.icon == "blue-head") {
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_blue.png"
                            } else if (tempTalk.icon == "black-head") {
                                talkClone.querySelector('.content-item-header img').src = "/images/debate_black.png"
                            } else if (tempTalk.icon == "blue-poster") {
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_blue.png"
                            } else if (tempTalk.icon == "black-poster") {
                                talkClone.querySelector('.content-item-header img').src = "/images/poster_black.png"
                            }

                            clone.querySelector('.content-items').appendChild(talkClone);
                        }
                        apendee3Element.appendChild(clone);
                    }
                }

                // this will show the info it in firebug console
                $(".content-item-header").on("click", function () {
                    $(this).next().slideToggle()
                });



            });

            $(".select-day > a").on("click", function () {

                $(".select-day > a").removeClass("selected")

                $(this).toggleClass("selected")

                $(".program-day").hide();

                $(".program-day:nth-child(" + ($(this).index() + 1) + ")").show();
            });


        });

    </script>
</body>

</html>